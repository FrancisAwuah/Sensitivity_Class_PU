{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PIG method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class prior for 20% of positive examples: 0.0000\n",
      "Class prior for 30% of positive examples: 0.0000\n",
      "Class prior for 40% of positive examples: 0.1667\n",
      "Class prior for 50% of positive examples: 0.7100\n",
      "F1-score for 20% of positive examples: 0.0000\n",
      "F1-score for 30% of positive examples: 0.0000\n",
      "F1-score for 40% of positive examples: 0.0769\n",
      "F1-score for 50% of positive examples: 0.2222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kofi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/kofi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/kofi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/kofi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/kofi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_10259/3324791534.py:54: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  y_pig = y_selected / class_prior\n",
      "/home/kofi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/kofi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/kofi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/kofi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_10259/3324791534.py:54: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  y_pig = y_selected / class_prior\n",
      "/home/kofi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/kofi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Load the data from the MAT-file\n",
    "data = sio.loadmat('/home/kofi/Downloads/Matlab/diabetes.mat')\n",
    "labels = data[\"labels\"]\n",
    "X = data[\"X\"]\n",
    "\n",
    "# Perform PCA on the data\n",
    "pca = PCA(n_components=2)\n",
    "X = pca.fit_transform(X)\n",
    "\n",
    "# Split the data into positive and unlabeled sets\n",
    "positive_indices = np.where(labels == 1)[0]\n",
    "unlabeled_indices = np.where(labels == 0)[0]\n",
    "X_positive = X[positive_indices, :]\n",
    "X_unlabeled = X[unlabeled_indices, :]\n",
    "\n",
    "# Set the percentage of positive examples to select\n",
    "percentages = [20, 30, 40, 50]\n",
    "\n",
    "# Initialize the F1-score array\n",
    "f1_scores = []\n",
    "\n",
    "# Iterate over the selected percentages\n",
    "for percent in percentages:\n",
    "    # Calculate the number of positive examples to select\n",
    "    num_examples = int(X_positive.shape[0] * percent / 100)\n",
    "\n",
    "    # Select a random subset of positive examples\n",
    "    selected_indices = np.random.choice(X_positive.shape[0], size=num_examples, replace=False)\n",
    "    X_selected = X_positive[selected_indices]\n",
    "    y_selected = np.ones(num_examples)\n",
    "\n",
    "    # Combine the selected positive examples with the unlabeled examples\n",
    "    X_combined = np.concatenate([X_selected, X_unlabeled])\n",
    "    y_combined = np.concatenate([y_selected, np.zeros(X_unlabeled.shape[0])])\n",
    "\n",
    "    # Calculate the class prior using cross-validation\n",
    "    model = LogisticRegression()\n",
    "    class_prior_scores = cross_val_score(model, X_combined, y_combined, cv=5, scoring=\"precision\")\n",
    "\n",
    "    # Calculate the average class prior across all folds\n",
    "    class_prior = np.mean(class_prior_scores)\n",
    "\n",
    "    print(f\"Class prior for {percent}% of positive examples: {class_prior:.4f}\")\n",
    "\n",
    "    # Perform PIG learning using the class prior\n",
    "    y_pig = y_selected / class_prior\n",
    "\n",
    "    # Combine the selected positive examples with the unlabeled examples\n",
    "    X_combined = np.concatenate([X_selected, X_unlabeled])\n",
    "    y_combined = np.concatenate([y_pig, np.zeros(X_unlabeled.shape[0])])\n",
    "\n",
    "    # Split the combined data into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_combined, y_combined, test_size=0.2, random_state=42)\n",
    "\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "    # Encode the target variable y\n",
    "    encoder = LabelEncoder()\n",
    "    y_train = encoder.fit_transform(y_train)\n",
    "    y_val = encoder.transform(y_val)\n",
    "\n",
    "    # Train a logistic regression model on the training data\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the validation data\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    # Calculate the F1-score and store it in the array\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Print the F1-scores for each percentage\n",
    "for i, percent in enumerate(percentages):\n",
    "    print(f\"F1-score for {percent}% of positive examples: {f1_scores[i]:.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform the CAL (Class prior Adjusted Labeling) method for PU learning with the calculated class priors, we need to adjust the probability threshold of the logistic regression classifier based on the class prior. Here's how we can modify the existing code to incorporate the CAL method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kofi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/kofi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/kofi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/kofi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/kofi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/kofi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/kofi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/kofi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class prior for 20% of positive examples: 0.0000\n",
      "F1-score for 20% of positive examples: 0.0000\n",
      "Class prior for 30% of positive examples: 0.5000\n",
      "F1-score for 30% of positive examples: 0.0488\n",
      "Class prior for 40% of positive examples: 0.2500\n",
      "F1-score for 40% of positive examples: 0.0893\n",
      "Class prior for 50% of positive examples: 0.6944\n",
      "F1-score for 50% of positive examples: 0.2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kofi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Load the data from the MAT-file\n",
    "data = sio.loadmat('/home/kofi/Downloads/Matlab/diabetes.mat')\n",
    "labels = data[\"labels\"]\n",
    "X = data[\"X\"]\n",
    "\n",
    "# Perform PCA on the data\n",
    "pca = PCA(n_components=2)\n",
    "X = pca.fit_transform(X)\n",
    "\n",
    "# Split the data into positive and unlabeled sets\n",
    "positive_indices = np.where(labels == 1)[0]\n",
    "unlabeled_indices = np.where(labels == 0)[0]\n",
    "X_positive = X[positive_indices, :]\n",
    "X_unlabeled = X[unlabeled_indices, :]\n",
    "\n",
    "# Set the percentage of positive examples to select\n",
    "percentages = [20, 30, 40, 50]\n",
    "\n",
    "# Initialize the F1-score array\n",
    "f1_scores = []\n",
    "\n",
    "# Iterate over the selected percentages\n",
    "for percent in percentages:\n",
    "    # Calculate the number of positive examples to select\n",
    "    num_examples = int(X_positive.shape[0] * percent / 100)\n",
    "\n",
    "    # Select a random subset of positive examples\n",
    "    selected_indices = np.random.choice(X_positive.shape[0], size=num_examples, replace=False)\n",
    "    X_selected = X_positive[selected_indices]\n",
    "    y_selected = np.ones(num_examples)\n",
    "\n",
    "    # Combine the selected positive examples with the unlabeled examples\n",
    "    X_combined = np.concatenate([X_selected, X_unlabeled])\n",
    "    y_combined = np.concatenate([y_selected, np.zeros(X_unlabeled.shape[0])])\n",
    "\n",
    "    # Calculate the class prior using cross-validation\n",
    "    model = LogisticRegression()\n",
    "    class_prior_scores = cross_val_score(model, X_combined, y_combined, cv=5, scoring=\"precision\")\n",
    "    class_prior = np.mean(class_prior_scores)\n",
    "\n",
    "    print(f\"Class prior for {percent}% of positive examples: {class_prior:.4f}\")\n",
    "\n",
    "    # Train a logistic regression classifier on the combined dataset\n",
    "    model.fit(X_combined, y_combined)\n",
    "\n",
    "    # Calculate the predicted probabilities for the unlabeled examples\n",
    "    proba_unlabeled = model.predict_proba(X_unlabeled)[:, 1]\n",
    "\n",
    "    # Adjust the probability threshold based on the class prior\n",
    "    threshold = class_prior / (1 - class_prior)\n",
    "\n",
    "    # Label the unlabeled examples based on the adjusted probability threshold\n",
    "    y_pred = (proba_unlabeled >= threshold).astype(int)\n",
    "\n",
    "    # Create an array with labels for all positive examples\n",
    "    y_true_all = np.concatenate([np.ones(X_positive.shape[0]), np.zeros(X_unlabeled.shape[0])])\n",
    "\n",
    "    # Select the labels for the selected positive examples\n",
    "    y_true = y_true_all[selected_indices]\n",
    "\n",
    "    # Predict the labels for all positive examples\n",
    "    y_pred_all = np.concatenate([model.predict(X_positive), np.zeros(X_unlabeled.shape[0])])\n",
    "\n",
    "    # Select the predictions for the selected positive examples\n",
    "    y_pred = y_pred_all[selected_indices]\n",
    "\n",
    "    # Calculate the F1-score for the labeled examples\n",
    "    f1 = f1_score(y_true, y_pred, pos_label=1)\n",
    "\n",
    "    # Add the F1-score to the array\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "    print(f\"F1-score for {percent}% of positive examples: {f1:.4f}\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method modification suggested by Bekker & Davis for PU learning involves modifying the class prior to incorporate the uncertainty about the true class labels of the unlabeled examples. Specifically, the modified class prior is given by:\n",
    "\n",
    "p_c = (1 - alpha) * p(y=c | labeled) + alpha * p(y=c)\n",
    "\n",
    "where p(y=c | labeled) is the empirical class frequency in the labeled examples, p(y=c) is the class prior estimated from the unlabeled and labeled examples, and alpha is a parameter that controls the amount of uncertainty incorporated from the unlabeled examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kofi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/kofi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/kofi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/kofi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified class prior for 20% of positive examples: 0.5000\n",
      "F1-score for 20% of positive examples: 0.0000\n",
      "Modified class prior for 30% of positive examples: 0.6000\n",
      "F1-score for 30% of positive examples: 0.0952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kofi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/kofi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/kofi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/kofi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/kofi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified class prior for 40% of positive examples: 0.6500\n",
      "F1-score for 40% of positive examples: 0.2459\n",
      "Modified class prior for 50% of positive examples: 0.8381\n",
      "F1-score for 50% of positive examples: 0.9150\n"
     ]
    }
   ],
   "source": [
    "# Initialize the alpha value\n",
    "alpha = 0.5\n",
    "\n",
    "# Iterate over the selected percentages\n",
    "for percent in percentages:\n",
    "    # Calculate the number of positive examples to select\n",
    "    num_examples = int(X_positive.shape[0] * percent / 100)\n",
    "\n",
    "    # Select a random subset of positive examples\n",
    "    selected_indices = np.random.choice(X_positive.shape[0], size=num_examples, replace=False)\n",
    "    X_selected = X_positive[selected_indices]\n",
    "    y_selected = np.ones(num_examples)\n",
    "\n",
    "    # Combine the selected positive examples with the unlabeled examples\n",
    "    X_combined = np.concatenate([X_selected, X_unlabeled])\n",
    "    y_combined = np.concatenate([y_selected, np.zeros(X_unlabeled.shape[0])])\n",
    "\n",
    "    # Calculate the empirical class frequency in the labeled examples\n",
    "    p_labeled = np.mean(y_selected)\n",
    "\n",
    "    # Calculate the class prior using cross-validation\n",
    "    model = LogisticRegression()\n",
    "    class_prior_scores = cross_val_score(model, X_combined, y_combined, cv=5, scoring=\"precision\")\n",
    "\n",
    "    # Calculate the average class prior across all folds\n",
    "    p_unlabeled = np.mean(class_prior_scores)\n",
    "\n",
    "    # Calculate the modified class prior\n",
    "    p_c = (1 - alpha) * p_labeled + alpha * p_unlabeled\n",
    "\n",
    "    print(f\"Modified class prior for {percent}% of positive examples: {p_c:.4f}\")\n",
    "\n",
    "    # Train a logistic regression model with the modified class prior\n",
    "    model = LogisticRegression(class_weight={1: p_c, 0: 1 - p_c})\n",
    "    model.fit(X_combined, y_combined)\n",
    "\n",
    "    # Predict the labels for all positive examples\n",
    "    y_pred_all = np.concatenate([model.predict(X_positive), np.zeros(X_unlabeled.shape[0])])\n",
    "\n",
    "    # Select the predictions for the selected positive examples\n",
    "    y_pred = y_pred_all[selected_indices]\n",
    "\n",
    "    # Create an array with labels for all positive examples\n",
    "    y_true_all = np.concatenate([np.ones(X_positive.shape[0]), np.zeros(X_unlabeled.shape[0])])\n",
    "\n",
    "    # Select the labels for the selected positive examples\n",
    "    y_true = y_true_all[selected_indices]\n",
    "\n",
    "    # Calculate the F1-score for the labeled examples\n",
    "    f1 = f1_score(y_true, y_pred, pos_label=1)\n",
    "\n",
    "    # Add the F1-score to the array\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "    print(f\"F1-score for {percent}% of positive examples: {f1:.4f}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code, we first initialize the alpha parameter to 0.5, which means that we are equally uncertain about the true class labels of the unlabeled examples and the empirical class frequency in the labeled examples. We then calculate the modified class prior p_c using this value of alpha, and train a logistic regression model with this modified class prior. Finally, we predict the labels for all positive examples, select the labels and predictions for the selected positive examples, and calculate the F1-score for these labeled examples."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the codes below are to be ignored\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score for 268 labeled examples: 0.9771\n"
     ]
    }
   ],
   "source": [
    "# Initialize the alpha value\n",
    "alpha = 0.5\n",
    "\n",
    "X_all = np.concatenate((X_positive, X_unlabeled), axis=0)\n",
    "\n",
    "\n",
    "# Find all examples that are not in the positive set\n",
    "X_negative = np.array([x for x in X_all if x not in X_positive])\n",
    "y_negative = np.zeros(X_negative.shape[0])\n",
    "\n",
    "\n",
    "# Initialize the labeled set with all positive examples\n",
    "X_labeled = X_positive.copy()\n",
    "y_labeled = np.ones(X_positive.shape[0])\n",
    "\n",
    "# Initialize the unlabeled set with all negative examples\n",
    "X_unlabeled = X_negative.copy()\n",
    "y_unlabeled = np.zeros(X_negative.shape[0])\n",
    "\n",
    "# Initialize the F1-scores array\n",
    "f1_scores = []\n",
    "\n",
    "# Initialize the stopping criterion\n",
    "stop = False\n",
    "\n",
    "while not stop:\n",
    "    # Combine the labeled and unlabeled sets\n",
    "    X_combined = np.concatenate([X_labeled, X_unlabeled])\n",
    "    y_combined = np.concatenate([y_labeled, y_unlabeled])\n",
    "\n",
    "    # Calculate the empirical class frequency in the labeled examples\n",
    "    p_labeled = np.mean(y_labeled)\n",
    "\n",
    "    # Calculate the class prior using cross-validation\n",
    "    model = LogisticRegression()\n",
    "    class_prior_scores = cross_val_score(model, X_combined, y_combined, cv=5, scoring=\"precision\")\n",
    "\n",
    "    # Calculate the average class prior across all folds\n",
    "    p_unlabeled = np.mean(class_prior_scores)\n",
    "\n",
    "    # Calculate the modified class prior\n",
    "    p_c = (1 - alpha) * p_labeled + alpha * p_unlabeled\n",
    "\n",
    "    # Train a logistic regression model with the modified class prior\n",
    "    model = LogisticRegression(class_weight={1: p_c, 0: 1 - p_c})\n",
    "    model.fit(X_combined, y_combined)\n",
    "\n",
    "    # Predict the labels for all examples\n",
    "    y_pred_all = model.predict(X_combined)\n",
    "\n",
    "    # Calculate the F1-score for the labeled examples\n",
    "    f1 = f1_score(y_labeled, y_pred_all[:y_labeled.shape[0]], pos_label=1)\n",
    "\n",
    "    # Add the F1-score to the array\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "    print(f\"F1-score for {X_labeled.shape[0]} labeled examples: {f1:.4f}\")\n",
    "\n",
    "    # Stop if the F1-score has plateaued or if the labeled set contains all positive examples\n",
    "    if len(f1_scores) > 1 and f1_scores[-1] == f1_scores[-2]:\n",
    "        stop = True\n",
    "    elif X_labeled.shape[0] == X_positive.shape[0]:\n",
    "        stop = True\n",
    "\n",
    "    # Rank the unlabeled examples by their predicted probability of being positive\n",
    "    proba_all = model.predict_proba(X_unlabeled)[:, 1]\n",
    "    indices = np.argsort(proba_all)[::-1]\n",
    "\n",
    "    # Select the most confident examples to add to the labeled set\n",
    "    num_examples = int(alpha * (X_labeled.shape[0] + X_unlabeled.shape[0]))\n",
    "    selected_indices = indices[:num_examples]\n",
    "    X_selected = X_unlabeled[selected_indices]\n",
    "    y_selected = np.ones(num_examples)\n",
    "\n",
    "    # Remove the selected examples from the unlabeled set\n",
    "    X_unlabeled = np.delete(X_unlabeled, selected_indices, axis=0)\n",
    "    y_unlabeled = np.delete(y_unlabeled, selected_indices)\n",
    "\n",
    "    # Add the selected examples to the labeled set\n",
    "    X_labeled = np.concatenate([X_labeled, X_selected])\n",
    "    y_labeled = np.concatenate([y_labeled, y_selected])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
