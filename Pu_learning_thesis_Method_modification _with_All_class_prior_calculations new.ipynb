{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class prior: 1.00\n",
      "F1-score: 0.436\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Load the data from the MAT-file\n",
    "data = sio.loadmat('/home/kofi/Downloads/Matlab/diabetes.mat')\n",
    "labels = data[\"labels\"]\n",
    "X = data[\"X\"]\n",
    "\n",
    "# Perform PCA on the data\n",
    "pca = PCA(n_components=2)\n",
    "X = pca.fit_transform(X)\n",
    "\n",
    "# Split the data into positive and unlabeled sets\n",
    "positive_indices = np.where(labels == 1)[0]\n",
    "unlabeled_indices = np.where(labels == 0)[0]\n",
    "X_positive = X[positive_indices, :]\n",
    "X_unlabeled = X[unlabeled_indices, :]\n",
    "\n",
    "# Split the positive examples and some of the unlabeled examples into training and validation sets\n",
    "X_train_positive, X_val_positive, y_train_positive, y_val_positive = train_test_split(X_positive, np.ones(X_positive.shape[0]), test_size=0.2, random_state=42)\n",
    "X_train_unlabeled, X_val_unlabeled, y_train_unlabeled, y_val_unlabeled = train_test_split(X_unlabeled, np.zeros(X_unlabeled.shape[0]), test_size=0.2, random_state=42)\n",
    "\n",
    "# Set the number of folds for cross-validation\n",
    "k = 5\n",
    "\n",
    "# Split the positive examples into k folds\n",
    "positive_folds = np.array_split(X_train_positive, k)\n",
    "\n",
    "# Estimate the class prior using cross-validation\n",
    "class_prior_cv = 0\n",
    "for fold in range(k):\n",
    "    # Split the remaining (K-1) folds into training and validation sets\n",
    "    train_indices = [i for i in range(k) if i != fold]\n",
    "    X_train = np.concatenate([positive_folds[i] for i in train_indices])\n",
    "    y_train = np.ones(X_train.shape[0])\n",
    "    \n",
    "    # Estimate the class prior using the current training set\n",
    "    current_class_prior = np.mean(y_train)\n",
    "    \n",
    "    # Add a small constant to the class prior estimate to avoid division by zero\n",
    "    current_class_prior = max(min(current_class_prior, 1 - 1e-10), 1e-10)\n",
    "    \n",
    "    # Add the current estimate to the running total\n",
    "    class_prior_cv += current_class_prior\n",
    "\n",
    "# Average the K estimates of the class prior\n",
    "class_prior_cv /= k\n",
    "\n",
    "# Calculate the class ratio\n",
    "class_ratio = class_prior_cv / (1 - class_prior_cv)\n",
    "\n",
    "# Train the logistic regression classifier on the positive and unlabeled training examples\n",
    "X_train = np.concatenate([X_train_positive, X_train_unlabeled])\n",
    "y_train = np.concatenate([np.ones(X_train_positive.shape[0]), np.zeros(X_train_unlabeled.shape[0])])\n",
    "classifier = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the validation set\n",
    "X_val = np.concatenate([X_val_positive, X_val_unlabeled])\n",
    "y_val_pred = classifier.predict(X_val)\n",
    "\n",
    "# Binarize the predicted scores\n",
    "y_val_bin = np.where(y_val_pred >= 0.5, 1, 0)\n",
    "\n",
    "\n",
    "# Calculate the F1 score for the validation set\n",
    "f1 = f1_score(np.concatenate([y_val_positive, y_val_unlabeled]), y_val_bin)\n",
    "\n",
    "# Print the F1 score and Class Prior\n",
    "print(\"Class prior: {:.2f}\".format(class_prior_cv))\n",
    "print(\"F1-score: {:.3f}\".format(f1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code trains a logistic regression classifier on a dataset of diabetes patients and non-diabetes patients. The dataset has two classes: positive and unlabeled. The positive class corresponds to patients with diabetes, while the unlabeled class corresponds to patients whose diabetes status is unknown. The goal is to estimate the F1 score of the classifier on the validation set.\n",
    "\n",
    "To achieve this, the code first performs PCA on the data to reduce its dimensionality. It then splits the data into positive and unlabeled sets and further splits the positive set and some of the unlabeled set into training and validation sets. Next, the code estimates the class prior by cross-validation. The class prior is the proportion of positive examples in the training set. The code then calculates the class ratio, which is the ratio of the class prior to the complement of the class prior. Finally, the code trains a logistic regression classifier on the positive and unlabeled training examples and predicts the labels for the validation set. It then binarizes the predicted scores, calculates the F1 score for the validation set, and prints the class prior and F1 score.\n",
    "\n",
    "The F1 score is a measure of the classifier's accuracy, combining the precision and recall. The class prior is the proportion of positive examples in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class prior: 0.35\n",
      "F1-score: 0.436\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Load the data from the MAT-file\n",
    "data = sio.loadmat('/home/kofi/Downloads/Matlab/diabetes.mat')\n",
    "labels = data[\"labels\"]\n",
    "X = data[\"X\"]\n",
    "\n",
    "# Perform PCA on the data\n",
    "pca = PCA(n_components=2)\n",
    "X = pca.fit_transform(X)\n",
    "\n",
    "# Split the data into positive and unlabeled sets\n",
    "positive_indices = np.where(labels == 1)[0]\n",
    "unlabeled_indices = np.where(labels == 0)[0]\n",
    "X_positive = X[positive_indices, :]\n",
    "X_unlabeled = X[unlabeled_indices, :]\n",
    "\n",
    "# Split the positive examples and some of the unlabeled examples into training and validation sets\n",
    "X_train_positive, X_val_positive, y_train_positive, y_val_positive = train_test_split(X_positive, np.ones(X_positive.shape[0]), test_size=0.2, random_state=42)\n",
    "X_train_unlabeled, X_val_unlabeled, y_train_unlabeled, y_val_unlabeled = train_test_split(X_unlabeled, np.zeros(X_unlabeled.shape[0]), test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Fit a logistic regression model on the training set\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the probability of the positive class for each example\n",
    "y_prob = clf.predict_proba(X)[:, 1]\n",
    "\n",
    "# Estimate the class prior using the model-based method\n",
    "class_prior_model = np.mean(y_prob)\n",
    "\n",
    "# Calculate the class ratio\n",
    "class_ratio = class_prior_model / (1 - class_prior_model)\n",
    "\n",
    "# Train the logistic regression classifier on the positive and unlabeled training examples\n",
    "X_train = np.concatenate([X_train_positive, X_train_unlabeled])\n",
    "y_train = np.concatenate([np.ones(X_train_positive.shape[0]), np.zeros(X_train_unlabeled.shape[0])])\n",
    "classifier = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the validation set\n",
    "X_val = np.concatenate([X_val_positive, X_val_unlabeled])\n",
    "y_val_pred = classifier.predict(X_val)\n",
    "\n",
    "# Binarize the predicted scores\n",
    "y_val_bin = np.where(y_val_pred >= 0.5, 1, 0)\n",
    "\n",
    "\n",
    "# Calculate the F1 score for the validation set\n",
    "f1 = f1_score(np.concatenate([y_val_positive, y_val_unlabeled]), y_val_bin)\n",
    "\n",
    "# Print the F1 score and Class Prior\n",
    "print(\"Class prior: {:.2f}\".format(class_prior_model))\n",
    "print(\"F1-score: {:.3f}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class prior: 0.35\n",
      "F1-score: 0.436\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Load the data from the MAT-file\n",
    "data = sio.loadmat('/home/kofi/Downloads/Matlab/diabetes.mat')\n",
    "labels = data[\"labels\"]\n",
    "X = data[\"X\"]\n",
    "\n",
    "# Perform PCA on the data\n",
    "pca = PCA(n_components=2)\n",
    "X = pca.fit_transform(X)\n",
    "\n",
    "# Split the data into positive and unlabeled sets\n",
    "positive_indices = np.where(labels == 1)[0]\n",
    "unlabeled_indices = np.where(labels == 0)[0]\n",
    "X_positive = X[positive_indices, :]\n",
    "X_unlabeled = X[unlabeled_indices, :]\n",
    "\n",
    "# Split the positive examples and some of the unlabeled examples into training and validation sets\n",
    "X_train_positive, X_val_positive, y_train_positive, y_val_positive = train_test_split(X_positive, np.ones(X_positive.shape[0]), test_size=0.2, random_state=42)\n",
    "X_train_unlabeled, X_val_unlabeled, y_train_unlabeled, y_val_unlabeled = train_test_split(X_unlabeled, np.zeros(X_unlabeled.shape[0]), test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit a logistic regression model on the training set\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the probability of the positive class for each example\n",
    "y_prob = clf.predict_proba(X)[:, 1]\n",
    "\n",
    "\n",
    "# Estimate the class prior using the MLE method\n",
    "class_prior_mle = np.mean(y_train)\n",
    "\n",
    "\n",
    "# Calculate the class ratio\n",
    "class_ratio = class_prior_mle / (1 - class_prior_mle)\n",
    "\n",
    "# Train the logistic regression classifier on the positive and unlabeled training examples\n",
    "X_train = np.concatenate([X_train_positive, X_train_unlabeled])\n",
    "y_train = np.concatenate([np.ones(X_train_positive.shape[0]), np.zeros(X_train_unlabeled.shape[0])])\n",
    "classifier = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the validation set\n",
    "X_val = np.concatenate([X_val_positive, X_val_unlabeled])\n",
    "y_val_pred = classifier.predict(X_val)\n",
    "\n",
    "# Binarize the predicted scores\n",
    "y_val_bin = np.where(y_val_pred >= 0.5, 1, 0)\n",
    "\n",
    "\n",
    "# Calculate the F1 score for the validation set\n",
    "f1 = f1_score(np.concatenate([y_val_positive, y_val_unlabeled]), y_val_bin)\n",
    "\n",
    "# Print the F1 score and Class Prior\n",
    "print(\"Class prior: {:.2f}\".format(class_prior_mle))\n",
    "print(\"F1-score: {:.3f}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class prior: 0.35\n",
      "F1-score: 0.436\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Load the data from the MAT-file\n",
    "data = sio.loadmat('/home/kofi/Downloads/Matlab/diabetes.mat')\n",
    "labels = data[\"labels\"]\n",
    "X = data[\"X\"]\n",
    "\n",
    "#Perform PCA on the data\n",
    "pca = PCA(n_components=2)\n",
    "X = pca.fit_transform(X)\n",
    "\n",
    "#Split the data into positive and unlabeled sets\n",
    "positive_indices = np.where(labels == 1)[0]\n",
    "unlabeled_indices = np.where(labels == 0)[0]\n",
    "X_positive = X[positive_indices, :]\n",
    "X_unlabeled = X[unlabeled_indices, :]\n",
    "\n",
    "#Split the positive examples and some of the unlabeled examples into training and validation sets\n",
    "X_train_positive, X_val_positive, y_train_positive, y_val_positive = train_test_split(X_positive, np.ones(X_positive.shape[0]), test_size=0.2, random_state=42)\n",
    "X_train_unlabeled, X_val_unlabeled, y_train_unlabeled, y_val_unlabeled = train_test_split(X_unlabeled, np.zeros(X_unlabeled.shape[0]), test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the logistic regression classifier on the positive and unlabeled training examples\n",
    "X_train = np.concatenate([X_train_positive, X_train_unlabeled])\n",
    "y_train = np.concatenate([np.ones(X_train_positive.shape[0]), np.zeros(X_train_unlabeled.shape[0])])\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the probability of the positive class for each example\n",
    "y_prob = clf.predict_proba(X)[:, 1]\n",
    "\n",
    "\n",
    "#Load the external dataset\n",
    "external_data = sio.loadmat('/home/kofi/Downloads/Matlab/diabetes.mat')\n",
    "external_labels = external_data[\"labels\"]\n",
    "\n",
    "#Calculate the class prior from the external dataset\n",
    "class_prior_external = np.mean(external_labels)\n",
    "\n",
    "#Calculate the class ratio\n",
    "class_ratio = class_prior_external / (1 - class_prior_external)\n",
    "\n",
    "# Train the logistic regression classifier on the positive and unlabeled training examples\n",
    "X_train = np.concatenate([X_train_positive, X_train_unlabeled])\n",
    "y_train = np.concatenate([np.ones(X_train_positive.shape[0]), np.zeros(X_train_unlabeled.shape[0])])\n",
    "classifier = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "#Predict the labels for the validation set\n",
    "X_val = np.concatenate([X_val_positive, X_val_unlabeled])\n",
    "y_val_pred = classifier.predict(X_val)\n",
    "\n",
    "#Binarize the predicted scores\n",
    "y_val_bin = np.where(y_val_pred >= 0.5, 1, 0)\n",
    "\n",
    "#Calculate the F1 score for the validation set\n",
    "f1 = f1_score(np.concatenate([y_val_positive, y_val_unlabeled]), y_val_bin)\n",
    "\n",
    "#Print the F1 score and Class Prior\n",
    "print(\"Class prior: {:.2f}\".format(class_prior_external))\n",
    "print(\"F1-score: {:.3f}\".format(f1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
